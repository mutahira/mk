Video Feature Extraction
Features extraction from videos is crucial and necessary step for various applications such as video compression, object recognition, activity recognition, and video summarization. It refers to the process of extracting meaningful and informative features from raw video frames or sequences. There are multiple types of feature extraction present (Salau, 2019) and we will discuss them with a taxonomy.
Visual feature extraction
Visual feature extraction refers to the process of extracting important visual information from an image or a video for further analysis or processing. One of its subtypes is handcraft feature extraction, in which the features are designed by domain experts based on prior knowledge of the video data. 
Handcraft feature
This technique has a useful role in various domains, and even the most critical healthcare applications used it, (Ozyurt, 2021) proposes an automated system for COVID-19 detection using deep learning techniques. The system uses fused dynamic exemplar pyramid feature extraction to extract relevant features from the images, and hybrid feature selection to select the most informative features for classification. The proposed system is evaluated on a dataset consisting of chest X-ray images and achieves an accuracy of 98.5% for COVID-19 detection, outperforming other state-of-the-art methods. Similarly, AlMubarak et al. (2019) proposed a hybrid approach for classifying cervical cancer digital histology images using a combination of deep learning and handcrafted features. The proposed method involves extracting handcrafted features such as colour and texture features using various techniques and combining them with deep learning features obtained from a pre-trained convolutional neural network (CNN) to achieve better classification accuracy. 

Wang et al. provide a comprehensive overview of the various techniques used for face feature extraction. The authors first introduce the importance of face feature extraction in various applications such as face recognition, facial expression analysis, and face detection. They then discuss the challenges associated with face feature extraction, including variations in pose, illumination, and occlusion. The article covers a range of handcrafted and deep learning-based feature extraction techniques for faces, including colour-based features, texture-based features, geometric-based features, and deep learning-based features. Another review by Guido's (2018) provides a comprehensive overview of entropy-based handcrafted feature extraction techniques for information fusion. The author highlights the importance of feature extraction as a crucial step in information fusion, particularly in applications where the data is high-dimensional, heterogeneous, and noisy. 
Deep Learning Features
Deep learning features are another type where the features are learned automatically by deep neural networks trained on large amounts of video data. Cui et al. (2019) present a deep learning feature extraction method for traffic sign recognition, which addresses the challenge of detecting and classifying traffic signs in complex and dynamic driving environments. The authors propose a deep learning architecture that consists of a convolutional neural network (CNN) for feature extraction and a support vector machine (SVM) for classification. The study highlights the potential of deep learning for improving the accuracy and efficiency of traffic sign recognition systems, which can contribute to enhancing road safety and reducing accidents. Li et al. (2020) propose a deep learning feature extraction and classification method for bearing fault diagnosis, which addresses the challenge of detecting and diagnosing bearing faults in industrial equipment. The authors employ a convolutional neural network (CNN) for feature extraction and a long short-term memory (LSTM) network for classification. The study highlights the potential of deep learning for improving the accuracy and efficiency of bearing fault diagnosis, which can contribute to reducing downtime and increasing productivity in industrial applications.
Fusion-based features
Fusion-based features are generated by fusing multiple types of handcrafted or deep-learning features to capture different aspects of the video data. Xu et al. (2017) propose a multimodal medical image feature fusion method for breast cancer diagnosis based on principal component analysis (PCA) and independent component analysis (ICA). The authors address the challenge of improving the accuracy and reliability of breast cancer diagnosis by combining multiple modalities of medical images, including ultrasound and mammography. The proposed method extracts features from each modality using PCA and ICA, respectively, and then fuses the features using a weighted sum. The study highlights the potential of multimodal image feature fusion for improving the accuracy of breast cancer diagnosis and demonstrates the effectiveness of PCA and ICA for feature extraction and fusion. Xu et al. (2018) present a novel approach to human action recognition using dynamic mode decomposition (DMD) and fusion of skeleton joints and motion history. The authors address the challenge of recognizing complex human actions from video sequences by fusing different types of features, including skeleton joints and motion history. The proposed method uses DMD to decompose the motion history into a set of dynamic modes, which are then combined with the skeleton joint features to form a joint feature representation.
Transfer Learning Features
Transfer Learning Features extraction is another type. These are features that are transferred from pre-trained models on related tasks or domains to reduce the amount of required labelled data and improve the feature quality. Wang et al. proposed a transfer learning-based approach using multi-task deep neural networks (MT-DNN) for fault diagnosis. It aims to address the issue of limited labelled data for fault diagnosis by transferring the knowledge learned from a source domain to a target domain with limited labelled data. Experiments were conducted on a bearing fault dataset, and the results showed that the proposed MT-DNN method achieved higher accuracy in fault diagnosis. The study demonstrates the potential of transfer learning and multi-task learning for addressing the challenges of limited labelled data in fault diagnosis applications. Similarly, Zhang et al. proposed a transfer learning-based multisource feature fusion method for hyperspectral image classification. The method involves extracting features from multiple sources, including hyperspectral data and auxiliary data, and fusing them using a transfer learning-based approach. The authors conducted experiments on two hyperspectral datasets, and the results showed that the proposed method achieved better classification accuracy than other state-of-the-art methods. The study demonstrates the potential of transfer learning and multisource feature fusion for improving the performance of hyperspectral image classification.

References
AlMubarak, H.A., Stanley, J., Guo, P., Long, R., Antani, S., Thoma, G., Zuna, R., Frazier, S. and Stoecker, W., 2019. A hybrid deep learning and handcrafted feature approach for cervical cancer digital histology image classification. International Journal of Healthcare Information Systems and Informatics (IJHISI), 14(2), pp.66-87.

Cui, W., Zhang, W., Liu, Y., Liu, X., & Wang, J. (2019). A deep learning feature extraction method for traffic sign recognition. Journal of Ambient Intelligence and Humanized Computing, 10(2), 501-508.

Guido, R.C., 2018. A tutorial review on entropy-based handcrafted feature extraction for information fusion. Information Fusion, 41, pp.161-175.

H. Wang, L. Liu, Y. Liu, and J. Song, "Transfer learning based on multi-task deep neural networks for fault diagnosis," Journal of Mechanical Science and Technology, vol. 33, no. 1, pp. 365-372, 2019

J. Xu, H. Chen, and X. Xie, "Multimodal medical image feature fusion for breast cancer diagnosis based on PCA and ICA," in 2017 IEEE International Conference on Signal and Image Processing Applications (ICSIPA), 2017, pp. 369-373.

Li, L., Li, Z., & Li, J. (2020). Deep learning feature extraction and classification for bearing fault diagnosis. Measurement, 165, 108210.

Ozyurt, F., Tuncer, T. and Subasi, A., 2021. An automated COVID-19 detection based on fused dynamic exemplar pyramid feature extraction and hybrid feature selection using deep learning. Computers in biology and medicine, 132, p.104356.

Salau, A.O. and Jain, S., 2019, March. Feature extraction: a survey of the types, techniques, applications. In 2019 international conference on signal processing and communication (ICSC) (pp. 158-164). IEEE.

Wang, H., Hu, J. and Deng, W., 2017. Face feature extraction: a complete review. IEEE Access, 6, pp.6001-6039.

